{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69af93dc-aeee-47b5-bf50-6a234eab7234",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 784])\n",
      "torch.Size([4, 20])\n",
      "torch.Size([4, 20])\n"
     ]
    }
   ],
   "source": [
    "#Cell to create the VAE functions\n",
    "\n",
    "#Import necessary packages\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "#intialize the VAE class\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim_fin = 200, z_dim = 20):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(400)\n",
    "        self.bn2 = nn.BatchNorm1d(200)\n",
    "        \n",
    "        #encoder\n",
    "        self.img_to_hid1 = nn.Linear(input_dim, 400)\n",
    "        self.hid1_to_hid2 = nn.Linear(400, hidden_dim_fin)\n",
    "        self.hid2_to_mu = nn.Linear(hidden_dim_fin, z_dim)\n",
    "        self.hid2_to_sigma = nn.Linear(hidden_dim_fin, z_dim)\n",
    "        \n",
    "        \n",
    "        #decoder\n",
    "        self.z_to_hid2 = nn.Linear(z_dim, hidden_dim_fin)\n",
    "        self.hid2_to_hid1 = nn.Linear(hidden_dim_fin, 400)\n",
    "        self.hid1_to_img = nn.Linear(400, input_dim)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    " #Steps: Input -> Hidden dim -> Mean & Std\n",
    "        # Mean & Std -> reparameterization trick applied \n",
    "        # from there that is passed through the decoder -> output\n",
    "        \n",
    "    def encode(self, x):\n",
    "        # q_phi(z|x)\n",
    "        \n",
    "        #apply batch normalization after first dimension reduction\n",
    "        h_1 = self.bn1(self.img_to_hid1(x))\n",
    "        #Pass the output through next dimension reduction function to get to the final hidden state then apply the relu activation function\n",
    "        h_fin = self.relu(self.hid1_to_hid2(h_1))\n",
    "        mu, sigma = self.hid2_to_mu(h_fin), self.hid2_to_sigma(h_fin)\n",
    "        \n",
    "        return mu, sigma\n",
    "    \n",
    "    \n",
    "    def decode(self, z):\n",
    "        #p_theta(x|z)\n",
    "        \n",
    "        #apply batch normalization after the first linear transformation\n",
    "        h_a = self.bn2(self.z_to_hid2(z))\n",
    "        #Apply the second linear transformation before relu activation function\n",
    "        h_b = self.relu(self.hid2_to_hid1(h_a))\n",
    "        \n",
    "        return torch.sigmoid(self.hid1_to_img(h_b)) #the values for the pixels have to be between 0 and 1 might be diff for other purposes\n",
    "    \n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, sigma = self.encode(x)\n",
    "        #reparameterization trick applied here\n",
    "        epsilon = torch.randn_like(sigma)\n",
    "        z_reparametrized = mu + sigma*epsilon\n",
    "        \n",
    "        x_reconstructed = self.decode(z_reparametrized)\n",
    "        \n",
    "        return x_reconstructed, mu, sigma\n",
    "        \n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    #To test that we wrote the function well we use a random x: Follow code\n",
    "    x = torch.randn(4, 28*28) # 28*28 input_dim = 784\n",
    "    vae = VAE(input_dim=784)\n",
    "    x_reconstructed, mu, sigma = vae(x)\n",
    "    print(x_reconstructed.shape)\n",
    "    print(mu.shape)\n",
    "    print(sigma.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f8627b4-4dba-4571-b97f-97215dad17b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/michael/Documents/Bioinformatics/593/Homework5'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22897364-3004-4939-ab98-71efd962b57b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:16, 113.12it/s, loss=8.08e+3]\n",
      "1875it [00:18, 100.75it/s, loss=9.03e+3]\n",
      "1875it [00:17, 106.61it/s, loss=7.84e+3]\n",
      "1875it [00:18, 101.20it/s, loss=8.32e+3]\n",
      "1875it [00:17, 106.08it/s, loss=7.38e+3]\n",
      "1875it [00:17, 104.63it/s, loss=7.97e+3]\n",
      "1875it [00:18, 102.32it/s, loss=6.83e+3]\n",
      "1875it [00:19, 96.46it/s, loss=6.57e+3] \n",
      "1875it [00:19, 97.05it/s, loss=6.54e+3] \n",
      "1875it [00:18, 102.43it/s, loss=7.33e+3]\n"
     ]
    }
   ],
   "source": [
    "#import necessaru packages for data and training \n",
    "import torch\n",
    "import torchvision.datasets as datasets # standard datasets\n",
    "from tqdm import tqdm\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader # this gives easier dataset management by creating mini batches etc\n",
    "\n",
    "#configuration\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "INPUT_DIM = 784\n",
    "HIDDEN_DIM = 200\n",
    "Z_DIM = 20\n",
    "NUM_EPOCHS = 10 \n",
    "BATCH_SIZE = 32 \n",
    "LR_RATE = 0.001\n",
    "\n",
    "\n",
    "#Dataset Loading\n",
    "dataset = datasets.MNIST(root=\"dataset/\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "train_loader = DataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "model = VAE(INPUT_DIM, HIDDEN_DIM, Z_DIM).to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR_RATE)\n",
    "loss_fn = nn.BCELoss(reduction=\"sum\")\n",
    "\n",
    "\n",
    "#Initiate training\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    loop = tqdm(enumerate(train_loader))\n",
    "    for i, (x, label) in loop:\n",
    "        #fowardpass\n",
    "        x = x.to(DEVICE).view(x.shape[0], INPUT_DIM)\n",
    "        x_reconstructed, mu, sigma = model(x)\n",
    "        \n",
    "        \n",
    "        #compute loss\n",
    "        reconstruction_loss = loss_fn(x_reconstructed, x)\n",
    "        kl_div = -torch.sum(1 + torch.log(sigma.pow(2)) - mu.pow(2) - sigma.pow(2)) # this will push the latent space towards standard gaussian\n",
    "        \n",
    "        #Backprop\n",
    "        loss = reconstruction_loss + kl_div\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b24a8b24-be59-4b82-9ef3-00bec2970e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/michael/Documents/Bioinformatics/Personal_Projects/VAE/Basic_VAE_on_MNIST_Data'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
